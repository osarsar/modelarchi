from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# ======================================================
# LOAD MODEL ‚Äî NLI
# ======================================================
MODEL_NAME = "joeddav/xlm-roberta-large-xnli"

print("üß† Chargement mod√®le NLI (Couche D)...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
model.eval()

LABELS = ["contradiction", "neutral", "entailment"]


# ======================================================
# NLI INFERENCE
# ======================================================
def nli_score(premise: str, hypothesis: str) -> dict:
    """
    premise = r√©f√©rence fiable
    hypothesis = news analys√©e
    """
    inputs = tokenizer(
        premise,
        hypothesis,
        return_tensors="pt",
        truncation=True,
        max_length=512
    )

    with torch.no_grad():
        logits = model(**inputs).logits

    probs = torch.softmax(logits, dim=1)[0]

    return {
        label: round(float(probs[i]), 3)
        for i, label in enumerate(LABELS)
    }


NEWS = (
    "Le minist√®re de l‚Äô√âducation a annonc√© la suspension imm√©diate "
    "du programme national de formation num√©rique des enseignants."
)



REFERENCE = (
    "Le minist√®re de l‚Äô√âducation a confirm√© la poursuite et le renforcement "
    "du programme national de formation num√©rique des enseignants."
)




result = nli_score(REFERENCE, NEWS)

print(result)
